<!DOCTYPE html>
<html lang="en">

<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Xiao He | LLM</title>
  <meta name="description" content="Homepage of Xiaohe He">
  <meta name="author" content="Xiaohe He">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href='https://fonts.googleapis.com/css?family=Raleway:400,300,600' rel='stylesheet' type='text/css'>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/skeleton/normalize.css>
  <link rel="stylesheet" href=/libs/external/skeleton/skeleton.css>
  <link rel="stylesheet" href=/libs/custom/my_css.css>
  <link rel="stylesheet" href=/libs/custom/blog.css>
  <link rel="stylesheet" href=/libs/custom/syntax.css>

  <!-- JQuery
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <script src=/libs/external/jquery-3.1.1.min.js></script>

  <!-- Font-Awesome
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/font-awesome-4.7.0/css/font-awesome.min.css>

  <!-- Skeleton tabs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/skeleton_tabs/skeleton-tabs.css>
  <script src=/libs/external/skeleton_tabs/skeleton-tabs.js></script>

  <!-- Timeline
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/timeline.css>

  <!-- Scripts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!--<link rel="stylesheet" href=/libs/external/github-prettify-theme.css>-->
  <script src=/libs/custom/my_js.js></script>

  <!-- Favicon
       –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!-- 
  <link rel="icon" type="image/png" href=/libs/icon.png>
  <link rel="shortcut icon" type="image/png" href=/libs/icon.png>
  -->

</head>

<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">

    <section class="header">
      <div class="row">
        <div class="three columns">
          <a href="/"><img class="u-max-full-width"
              src='/assets/profile-pics/hexh.jpg'></a>
        </div>
        <div class="nine columns main-description">
          <h1>Xiao He</h1>
          <p></p>
          <p></p>
          <p>hithxh [AT] gmail.com</p>
          <p>
            <!-- <span onclick="window.open('')" style="cursor: pointer">
                <i class="fa fa-twitter" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('')" style="cursor: pointer">
                <i class="fa fa-linkedin-square" aria-hidden="true"></i>
              </span> -->

            <span onclick="window.open('https://github.com/hithxh')" style="cursor: pointer">
              <i class="fa fa-github" aria-hidden="true"></i>
            </span>
          </p>
        </div>
      </div>
    </section>

    <div class="navbar-spacer"></div>
    <nav class="navbar">
      <div class="container">
        <ul class="navbar-list">
          <li class="navbar-item"><a class="navbar-link" href=/index.html#bio>Bio</a>
          </li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#publications>Publications</a></li>
          <!---
          <li class="navbar-item"><a class="navbar-link" href=/index.html#people>People</a></li>
          --->
          <li class="navbar-item"><a class="navbar-link" href=/index.html#resume>Resume</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/blog.html>Blog</a></li>
        </ul>
      </div>
    </nav>

    <div class="docs-section">
  <h4>LLM</h4>
  <p><i>December 30, 2025</i></p>

  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <div class="blog-post-content">
    <h1 id="pre-training">Pre-training</h1>
<h2 id="part-1--core-transformer-architecture">Part 1 — Core Transformer Architecture</h2>

<ul>
  <li><strong>1.1</strong> Positional embeddings (absolute learned vs. sinusoidal)</li>
  <li><strong>1.2</strong> Self-attention from first principles (manual computation with a tiny example)</li>
  <li><strong>1.3</strong> Building a <em>single attention head</em> in PyTorch</li>
  <li><strong>1.4</strong> Multi-head attention (splitting, concatenation, projections)</li>
  <li><strong>1.5</strong> Feed-forward networks (MLP layers) — GELU, dimensionality expansion</li>
  <li><strong>1.5</strong> Residual connections &amp; <strong>LayerNorm</strong></li>
  <li><strong>1.6</strong> Stacking into a full Transformer block</li>
</ul>

<h2 id="part-2--training-a-tiny-llm">Part 2 — Training a Tiny LLM</h2>

<ul>
  <li><strong>2.1</strong> Byte-level tokenization</li>
  <li><strong>2.2</strong> Dataset batching &amp; shifting for next-token prediction</li>
  <li><strong>2.3</strong> Cross-entropy loss &amp; label shifting</li>
  <li><strong>2.4</strong> Training loop from scratch (no Trainer API)</li>
  <li><strong>2.5</strong> Sampling: temperature, top-k, top-p</li>
  <li><strong>2.6</strong> Evaluating loss on val set</li>
</ul>

<h2 id="part-3--modernizing-the-architecture">Part 3 — Modernizing the Architecture</h2>

<ul>
  <li><strong>3.1</strong> <strong>RMSNorm</strong> (replace LayerNorm, compare gradients &amp; convergence)</li>
  <li><strong>3.2</strong> <strong>RoPE</strong> (Rotary Positional Embeddings) — theory &amp; code</li>
  <li><strong>3.3</strong> SwiGLU activations in MLP</li>
  <li><strong>3.4</strong> KV cache for faster inference</li>
  <li><strong>3.5</strong> Sliding-window attention &amp; <strong>attention sink</strong></li>
  <li><strong>3.6</strong> Rolling buffer KV cache for streaming</li>
</ul>

<h2 id="part-4--scaling-up">Part 4 — Scaling Up</h2>

<ul>
  <li><strong>4.1</strong> Switching from byte-level to BPE tokenization</li>
  <li><strong>4.2</strong> Gradient accumulation &amp; mixed precision</li>
  <li><strong>4.3</strong> Learning rate schedules &amp; warmup</li>
  <li><strong>4.4</strong> Checkpointing &amp; resuming</li>
  <li><strong>4.5</strong> Logging &amp; visualization (TensorBoard / wandb)</li>
</ul>

<h2 id="part-5--mixture-of-experts-moe">Part 5 — Mixture-of-Experts (MoE)</h2>

<ul>
  <li><strong>5.1</strong> MoE theory: expert routing, gating networks, and load balancing</li>
  <li><strong>5.2</strong> Implementing MoE layers in PyTorch</li>
  <li><strong>5.3</strong> Combining MoE with dense layers for hybrid architectures</li>
</ul>

<h1 id="finetuning">Finetuning</h1>
<h2 id="part-6--supervised-fine-tuning-sft">Part 6 — Supervised Fine-Tuning (SFT)</h2>

<ul>
  <li><strong>6.1</strong> Instruction dataset formatting (prompt + response)</li>
  <li><strong>6.2</strong> Causal LM loss with masked labels</li>
  <li><strong>6.3</strong> Curriculum learning for instruction data</li>
  <li><strong>6.4</strong> Evaluating outputs against gold responses</li>
</ul>

<h1 id="rl">RL</h1>
<h2 id="part-7--reward-modeling">Part 7 — Reward Modeling</h2>

<ul>
  <li><strong>7.1</strong> Preference datasets (pairwise rankings)</li>
  <li><strong>7.2</strong> Reward model architecture (transformer encoder)</li>
  <li><strong>7.3</strong> Loss functions: Bradley–Terry, margin ranking loss</li>
  <li><strong>7.4</strong> Sanity checks for reward shaping</li>
</ul>

<h2 id="part-8--rlhf-with-ppo">Part 8 — RLHF with PPO</h2>

<ul>
  <li><strong>8.1</strong> Policy network: our base LM (from SFT) with a value head for reward prediction.</li>
  <li><strong>8.2</strong> Reward signal: provided by the reward model trained in Part 7.</li>
  <li><strong>8.3</strong> PPO objective: balance between maximizing reward and staying close to the SFT policy (KL penalty).</li>
  <li><strong>8.4</strong> Training loop: sample prompts → generate completions → score with reward model → optimize policy via PPO.</li>
  <li><strong>8.5</strong> Logging &amp; stability tricks: reward normalization, KL-controlled rollout length, gradient clipping.</li>
</ul>

<h2 id="part-9--rlhf-with-grpo">Part 9 — RLHF with GRPO</h2>

<ul>
  <li><strong>9.1</strong> Group-relative baseline: instead of a value head, multiple completions are sampled per prompt and their rewards are normalized against the group mean.</li>
  <li><strong>9.2</strong> Advantage calculation: each completion’s advantage = (reward – group mean reward), broadcast to all tokens in that trajectory.</li>
  <li><strong>9.3</strong> Objective: PPO-style clipped policy loss, but <em>policy-only</em> (no value loss).</li>
  <li><strong>9.4</strong> KL regularization: explicit KL(π‖π_ref) penalty term added directly to the loss (not folded into the advantage).</li>
  <li><strong>9.5</strong> Training loop differences: sample <code class="language-plaintext highlighter-rouge">k</code> completions per prompt → compute rewards → subtract per-prompt mean → apply GRPO loss with KL penalty.</li>
</ul>

<h1 id="agent">Agent</h1>

<h2 id="agentic-rl">Agentic RL</h2>

  </div>

  <div style="margin-top: 50px;">
    <a href="/blog.html" class="button">Back to Blog</a>
  </div>
</div>

    <div class="footer">
      <div class="row">
        <div class="four columns">
          Xiao He
        </div>
        <div class="four columns">
          hithxh [AT] gmail.com
        </div>
        <div class="four columns">
          <!-- <span onclick="window.open('')" style="cursor: pointer">
            <i class="fa fa-twitter" aria-hidden="true"></i>
          </span>
          <span onclick="window.open('')" style="cursor: pointer">
            <i class="fa fa-linkedin-square" aria-hidden="true"></i>
          </span> -->
          <span onclick="window.open('https://github.com/hithxh')" style="cursor: pointer">
            <i class="fa fa-github" aria-hidden="true"></i>
          </span>
        </div>
      </div>
    </div>

  </div>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');

</script>

  <!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>

</html>